{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2249a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kjw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kjw/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "sentence = \"James is working at Disney in London\"\n",
    "# 토큰화 후 품사 태깅\n",
    "tokenized_sentence = pos_tag(word_tokenize(sentence))\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862f6b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON James/NNP)\n",
      "  is/VBZ\n",
      "  working/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Disney/NNP)\n",
      "  in/IN\n",
      "  (GPE London/NNP))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/kjw/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/kjw/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "ner_sentence = ne_chunk(tokenized_sentence)\n",
    "print(ner_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1969338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a3966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url=\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\"\n",
    "urllib.request.urlretrieve(train_url, filename=\"train.txt\")\n",
    "\n",
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
    "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31b304b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수: 14041\n",
      "첫번째 샘플: [['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"전체 샘플 개수: {len(tagged_sentences)}\")\n",
    "print(f'첫번째 샘플: {tagged_sentences[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280a0590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 문장: ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "첫번째 샘플의 레이블: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 문장 샘플을 1개씩 불러온다.\n",
    "    # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장\n",
    "    sentence, tag_info = zip(*tagged_sentence) \n",
    "    \n",
    "    # 각 샘플에서 단어 정보만 저장\n",
    "    sentences.append(list(sentence)) \n",
    "    \n",
    "    # 각 샘플에서 개체명 태깅 정보만 저장\n",
    "    ner_tags.append(list(tag_info)) \n",
    "    \n",
    "print(f'첫번째 샘플의 문장: {sentences[0]}')\n",
    "print(f'첫번째 샘플의 레이블: {ner_tags[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3ecae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이:113\n",
      "샘플의 평균 길이: 14.501887329962253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'샘플의 최대 길이:{max(len(sentence) for sentence in sentences)}')\n",
    "print(f'샘플의 평균 길이: {sum(map(len, sentences))/len(sentences)}')\n",
    "plt.hist([len(sentence) for sentence in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3357753",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 4000\n",
      "개체명 태깅 정보 집합의 크기: 10\n",
      "첫번째 샘플의 문장: [989, 1, 205, 629, 7, 3939, 216, 1, 3]\n",
      "첫번째 샘플의 레이블: [4, 1, 7, 1, 1, 1, 7, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4000\n",
    "# src_tokenizer: 문장 데이터\n",
    "src_tokenizer = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "#tar_tokenizer: 개체명 태깅 정보\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)\n",
    "\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print(f'단어 집합의 크기: {vocab_size}')\n",
    "print(f'개체명 태깅 정보 집합의 크기: {tag_size}')\n",
    "\n",
    "# 정수 인코딩\n",
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(ner_tags)\n",
    "\n",
    "print(f'첫번째 샘플의 문장: {X_train[0]}')\n",
    "print(f'첫번째 샘플의 레이블: {y_train[0]}')\n",
    "#print(src_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c274de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장: ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "빈도수가 낮은 단어가 OOV 처리된 문장: ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
     ]
    }
   ],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "\n",
    "decoded = []\n",
    "for index in X_train[0] : # 첫번째 샘플 안의 각 정수로 변환된 단어에 대해서\n",
    "    decoded.append(index_to_word[index]) # 단어로 변환\n",
    "\n",
    "print(f'기존 문장: {sentences[0]}')\n",
    "print(f'빈도수가 낮은 단어가 OOV 처리된 문장: {decoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95293261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기: (8424, 70)\n",
      "훈련 샘플 레이블의 크기: (8424, 70, 10)\n",
      "검증 샘플 문장의 크기: (2809, 70)\n",
      "검증 샘플 레이블의 크기: (2809, 70, 10)\n",
      "테스트 샘플 문장의 크기: (2808, 70)\n",
      "테스트 샘플 레이블의 크기: (2808, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, \n",
    "                                                    test_size=.4, \n",
    "                                                    random_state=777)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, \n",
    "                                                    test_size=.5, \n",
    "                                                    random_state=777)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)\n",
    "y_val = to_categorical(y_val, num_classes=tag_size)\n",
    "\n",
    "print(f'훈련 샘플 문장의 크기: {X_train.shape}')\n",
    "print(f'훈련 샘플 레이블의 크기: {y_train.shape}')\n",
    "print(f'검증 샘플 문장의 크기: {X_val.shape}')\n",
    "print(f'검증 샘플 레이블의 크기: {y_val.shape}')\n",
    "print(f'테스트 샘플 문장의 크기: {X_test.shape}')\n",
    "print(f'테스트 샘플 레이블의 크기: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8197db08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 21:50:55.051958: I tensorflow/stream_executor/stream.cc:4442] [stream=0x55e16e389160,impl=0x55e16e389450] INTERNAL: stream did not block host until done; was already in an error state\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Qr: stream did not block host until done; was already in an error state [Op:Qr]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size, output_dim\u001b[38;5;241m=\u001b[39membedding_dim, \n\u001b[1;32m     11\u001b[0m                     input_length\u001b[38;5;241m=\u001b[39mmax_len, mask_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(TimeDistributed(Dense(tag_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m), \n\u001b[1;32m     17\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:621\u001b[0m, in \u001b[0;36mOrthogonal.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mrandom_normal(flat_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# Compute the qr factorization\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m q, r \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqr\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# Make Q uniform\u001b[39;00m\n\u001b[1;32m    623\u001b[0m d \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mtensor_diag_part(r)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Qr: stream did not block host until done; was already in an error state [Op:Qr]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
    "                    input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(X_train, y_train, \n",
    "                   batch_size=128, \n",
    "                   epochs=30, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(history,name) :\n",
    "    plt.title(f\"{name.upper()}\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(f\"{name.lower()}\")\n",
    "    value = history.history.get(name)\n",
    "    val_value = history.history.get(f\"val_{name}\",None)\n",
    "    epochs = range(1, len(value)+1)\n",
    "    plt.plot(epochs, value, 'b-', label=f'training {name}')\n",
    "    if val_value is not None :\n",
    "        plt.plot(epochs, val_value, 'r:', label=f'validation {name}')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.05, 1.2) , \n",
    "               fontsize=10 , ncol=1)\n",
    "    \n",
    "def plot_history(history) :\n",
    "    key_value = list(set([i.split(\"val_\")[-1] for i in list(history.history.keys())]))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for idx , key in enumerate(key_value) :\n",
    "        plt.subplot(1, len(key_value), idx+1)\n",
    "        vis(history, key)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1713de",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "\n",
    "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = model.predict(np.array([X_test[i]]))\n",
    "\n",
    "# 확률 벡터를 정수 레이블로 변경.\n",
    "y_predicted = np.argmax(y_predicted, axis=-1)\n",
    "\n",
    "# 원-핫 벡터를 정수 인코딩으로 변경.\n",
    "labels = np.argmax(y_test[i], -1)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], \n",
    "                                      index_to_ner[tag].upper(), \n",
    "                                      index_to_ner[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7485fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 \n",
    "            #  1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)            \n",
    "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. '\n",
    "            # PAD'는 'O'로 변경.\n",
    "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result\n",
    "\n",
    "y_predicted = model.predict([X_test])\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
